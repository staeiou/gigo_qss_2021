{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIGO revisited\n",
    "## Script 1: Inter-Rater Reliability Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "See `requirements.txt` for specific version numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.11.1)\n",
      "Requirement already satisfied: openpyxl in /home/sgeiger/.local/lib/python3.8/site-packages (3.0.7)\n",
      "Requirement already satisfied: simpledorff in /home/sgeiger/.local/lib/python3.8/site-packages (0.0.2)\n",
      "Requirement already satisfied: et-xmlfile in /home/sgeiger/.local/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.8/site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.3.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas seaborn openpyxl simpledorff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import ticker\n",
    "import simpledorff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Krippendorff's alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/all_labels_hashed.xlsx\", sheet_name=None, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Excel file has one sheet per question. Rows are items, with one column for each labeler's response. `pd.read_excel()` puts each sheet in a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['original_classification_task', 'classification_outcome', 'labels_from_human_annotation', 'human_annotation_for_training_', 'used_original_human_annotation', 'original_human_annotation_sour', 'prescreening_for_crowdwork', 'annotator_compensation', 'training_for_human_annotators', 'formal_instructions_', 'multiple_annotator_overlap', 'synthesis_of_annotator_overlap', 'reported_inter-annotator_agree', 'total_num_of_human_annotators', 'median_num_of_annotators_per_i', 'link_to_dataset_available'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL hash</th>\n",
       "      <th>Annotator 1</th>\n",
       "      <th>Annotator 2</th>\n",
       "      <th>Annotator 3</th>\n",
       "      <th>Annotator 4</th>\n",
       "      <th>Annotator 5</th>\n",
       "      <th>Annotator 6</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e6ec7fb47f277e38f25e35238ca9685ab97c6f0caae10...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2421ef5ad32c44fd217fa11cae35504247a6e2b7a3f94e...</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1e0bdeb7f8a0fdd7bc3ee02ca01673f4a5433241095be9...</td>\n",
       "      <td>Unsure</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3714e16720b27a5a102dde1dd7cfe0201d52a65e4f486f...</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29bab7d76596226416eead7306f540340a0cab99338ec1...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>929a8c77b1e75c26130344dca269759b44ed01ed53eba7...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>e6da1957824240f2b7de01f1d7b54def296924d357ff95...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>a747196b27097e349348547272305007a128b49a159449...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>d29948f93b01194845e2ebc5c5899c38e73cd3d5d2d843...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>867ed66f03805e58062d40b2f3b9d333fc81962ef3681e...</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              URL hash Annotator 1  \\\n",
       "0    4e6ec7fb47f277e38f25e35238ca9685ab97c6f0caae10...         yes   \n",
       "1    2421ef5ad32c44fd217fa11cae35504247a6e2b7a3f94e...         yes   \n",
       "2    1e0bdeb7f8a0fdd7bc3ee02ca01673f4a5433241095be9...      Unsure   \n",
       "3    3714e16720b27a5a102dde1dd7cfe0201d52a65e4f486f...         yes   \n",
       "4    29bab7d76596226416eead7306f540340a0cab99338ec1...         yes   \n",
       "..                                                 ...         ...   \n",
       "195  929a8c77b1e75c26130344dca269759b44ed01ed53eba7...         yes   \n",
       "196  e6da1957824240f2b7de01f1d7b54def296924d357ff95...         yes   \n",
       "197  a747196b27097e349348547272305007a128b49a159449...         yes   \n",
       "198  d29948f93b01194845e2ebc5c5899c38e73cd3d5d2d843...         yes   \n",
       "199  867ed66f03805e58062d40b2f3b9d333fc81962ef3681e...         yes   \n",
       "\n",
       "    Annotator 2 Annotator 3 Annotator 4 Annotator 5 Annotator 6 Final  \n",
       "0           yes         yes         yes         yes               N/A  \n",
       "1                       yes         yes         yes               yes  \n",
       "2           yes         yes         yes         yes               yes  \n",
       "3                       yes         yes         yes               yes  \n",
       "4           yes         yes         yes         yes               yes  \n",
       "..          ...         ...         ...         ...         ...   ...  \n",
       "195         yes         yes                     yes               yes  \n",
       "196         yes         yes                      no               yes  \n",
       "197         yes         yes                      no               yes  \n",
       "198         yes         yes                     yes               yes  \n",
       "199                     yes                                       yes  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_classification_task']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data\n",
    "First, some values aren't formatted in the way they need to for comparisons to work. Convert all fields to lowercase strings. \n",
    "\n",
    "1. Blanks were np.nan, those got converted to \"nan\" strings in the prior step, so replace those back.\n",
    "1. Replace \"N/A\" with \"answered NA\" because some libraries like to convert \"N/A\" to np.nan on their own\n",
    "1. Convert any blank strings into np.nan\n",
    "1. Replace \"-\" with \"no information\" (these were how the instuctions said to report no info on the number of annotators questions\")\n",
    "1. Replace \"unsure\" with np.nan, which makes unsures the same as blanks for IRR purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df = df.apply(lambda x: x.astype(str).str.lower())\n",
    "    df = df.replace(to_replace=\"nan\",value=np.nan)    \n",
    "    df = df.replace(to_replace=\"n/a\",value=\"answered NA\")  # because some code keeps wanting to turn N/A into np.nan\n",
    "    df = df.replace(to_replace=\"\",value=np.nan)\n",
    "    df = df.replace(to_replace=\"-\", value=\"no information\") # for the number of annotators questions\n",
    "    df = df.replace(to_replace=\"unsure\",value=np.nan)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean each sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet in list(df.keys()):\n",
    "    df[sheet] = clean_df(df[sheet])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL hash</th>\n",
       "      <th>Annotator 1</th>\n",
       "      <th>Annotator 2</th>\n",
       "      <th>Annotator 3</th>\n",
       "      <th>Annotator 4</th>\n",
       "      <th>Annotator 5</th>\n",
       "      <th>Annotator 6</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e6ec7fb47f277e38f25e35238ca9685ab97c6f0caae10...</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>no information</td>\n",
       "      <td>no information</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>answered NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2421ef5ad32c44fd217fa11cae35504247a6e2b7a3f94e...</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no information</td>\n",
       "      <td>no information</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>answered NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1e0bdeb7f8a0fdd7bc3ee02ca01673f4a5433241095be9...</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>no information</td>\n",
       "      <td>no information</td>\n",
       "      <td>no information</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>answered NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3714e16720b27a5a102dde1dd7cfe0201d52a65e4f486f...</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no information</td>\n",
       "      <td>no information</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29bab7d76596226416eead7306f540340a0cab99338ec1...</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>no information</td>\n",
       "      <td>no information</td>\n",
       "      <td>no information</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>answered NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>929a8c77b1e75c26130344dca269759b44ed01ed53eba7...</td>\n",
       "      <td>no information</td>\n",
       "      <td>no information</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>answered NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>e6da1957824240f2b7de01f1d7b54def296924d357ff95...</td>\n",
       "      <td>no information</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>a747196b27097e349348547272305007a128b49a159449...</td>\n",
       "      <td>2</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>answered NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>d29948f93b01194845e2ebc5c5899c38e73cd3d5d2d843...</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>no information</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>867ed66f03805e58062d40b2f3b9d333fc81962ef3681e...</td>\n",
       "      <td>no information</td>\n",
       "      <td>NaN</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>answered NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              URL hash     Annotator 1  \\\n",
       "0    4e6ec7fb47f277e38f25e35238ca9685ab97c6f0caae10...     answered NA   \n",
       "1    2421ef5ad32c44fd217fa11cae35504247a6e2b7a3f94e...     answered NA   \n",
       "2    1e0bdeb7f8a0fdd7bc3ee02ca01673f4a5433241095be9...     answered NA   \n",
       "3    3714e16720b27a5a102dde1dd7cfe0201d52a65e4f486f...     answered NA   \n",
       "4    29bab7d76596226416eead7306f540340a0cab99338ec1...     answered NA   \n",
       "..                                                 ...             ...   \n",
       "195  929a8c77b1e75c26130344dca269759b44ed01ed53eba7...  no information   \n",
       "196  e6da1957824240f2b7de01f1d7b54def296924d357ff95...  no information   \n",
       "197  a747196b27097e349348547272305007a128b49a159449...               2   \n",
       "198  d29948f93b01194845e2ebc5c5899c38e73cd3d5d2d843...     answered NA   \n",
       "199  867ed66f03805e58062d40b2f3b9d333fc81962ef3681e...  no information   \n",
       "\n",
       "        Annotator 2     Annotator 3     Annotator 4  Annotator 5 Annotator 6  \\\n",
       "0       answered NA  no information  no information          NaN         NaN   \n",
       "1               NaN  no information  no information  answered NA         NaN   \n",
       "2    no information  no information  no information  answered NA         NaN   \n",
       "3               NaN  no information  no information  answered NA         NaN   \n",
       "4    no information  no information  no information  answered NA         NaN   \n",
       "..              ...             ...             ...          ...         ...   \n",
       "195  no information     answered NA             NaN  answered NA         NaN   \n",
       "196               2               2             NaN  answered NA         NaN   \n",
       "197     answered NA     answered NA             NaN  answered NA         NaN   \n",
       "198  no information     answered NA             NaN  answered NA         NaN   \n",
       "199             NaN     answered NA             NaN          NaN         NaN   \n",
       "\n",
       "              Final  \n",
       "0       answered NA  \n",
       "1       answered NA  \n",
       "2       answered NA  \n",
       "3                10  \n",
       "4       answered NA  \n",
       "..              ...  \n",
       "195     answered NA  \n",
       "196               2  \n",
       "197     answered NA  \n",
       "198  no information  \n",
       "199     answered NA  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_num_of_human_annotators']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `simpledorff` library expects a melted dataframe in the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL hash</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e6ec7fb47f277e38f25e35238ca9685ab97c6f0caae10...</td>\n",
       "      <td>Annotator 1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2421ef5ad32c44fd217fa11cae35504247a6e2b7a3f94e...</td>\n",
       "      <td>Annotator 1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1e0bdeb7f8a0fdd7bc3ee02ca01673f4a5433241095be9...</td>\n",
       "      <td>Annotator 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3714e16720b27a5a102dde1dd7cfe0201d52a65e4f486f...</td>\n",
       "      <td>Annotator 1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29bab7d76596226416eead7306f540340a0cab99338ec1...</td>\n",
       "      <td>Annotator 1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>929a8c77b1e75c26130344dca269759b44ed01ed53eba7...</td>\n",
       "      <td>Final</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>e6da1957824240f2b7de01f1d7b54def296924d357ff95...</td>\n",
       "      <td>Final</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>a747196b27097e349348547272305007a128b49a159449...</td>\n",
       "      <td>Final</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>d29948f93b01194845e2ebc5c5899c38e73cd3d5d2d843...</td>\n",
       "      <td>Final</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>867ed66f03805e58062d40b2f3b9d333fc81962ef3681e...</td>\n",
       "      <td>Final</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               URL hash     variable value\n",
       "0     4e6ec7fb47f277e38f25e35238ca9685ab97c6f0caae10...  Annotator 1   yes\n",
       "1     2421ef5ad32c44fd217fa11cae35504247a6e2b7a3f94e...  Annotator 1   yes\n",
       "2     1e0bdeb7f8a0fdd7bc3ee02ca01673f4a5433241095be9...  Annotator 1   NaN\n",
       "3     3714e16720b27a5a102dde1dd7cfe0201d52a65e4f486f...  Annotator 1   yes\n",
       "4     29bab7d76596226416eead7306f540340a0cab99338ec1...  Annotator 1   yes\n",
       "...                                                 ...          ...   ...\n",
       "1395  929a8c77b1e75c26130344dca269759b44ed01ed53eba7...        Final   yes\n",
       "1396  e6da1957824240f2b7de01f1d7b54def296924d357ff95...        Final   yes\n",
       "1397  a747196b27097e349348547272305007a128b49a159449...        Final   yes\n",
       "1398  d29948f93b01194845e2ebc5c5899c38e73cd3d5d2d843...        Final   yes\n",
       "1399  867ed66f03805e58062d40b2f3b9d333fc81962ef3681e...        Final   yes\n",
       "\n",
       "[1400 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = df['original_classification_task'].melt(id_vars=\"URL hash\")\n",
    "q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a sample to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6704685927345297"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpledorff.calculate_krippendorffs_alpha_for_df(q1,experiment_col='URL hash',\n",
    "                                                 annotator_col='variable',\n",
    "                                                 class_col='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A loop that iterates through each sheet in the dictionary, melts the sheet, calculates Ka for that melted sheet, and stores the Ka in a new dictionary `ka_dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_classification_task\n",
      "0.6704685927345297\n",
      "classification_outcome\n",
      "0.520310339963324\n",
      "labels_from_human_annotation\n",
      "0.517077633724152\n",
      "human_annotation_for_training_\n",
      "0.5168762194608635\n",
      "used_original_human_annotation\n",
      "0.49764243839882727\n",
      "original_human_annotation_sour\n",
      "0.3295543968704172\n",
      "prescreening_for_crowdwork\n",
      "0.09716769760445754\n",
      "annotator_compensation\n",
      "0.3427458775989042\n",
      "training_for_human_annotators\n",
      "0.3639740074970065\n",
      "formal_instructions_\n",
      "0.33656217062897187\n",
      "multiple_annotator_overlap\n",
      "0.3703134478611023\n",
      "synthesis_of_annotator_overlap\n",
      "0.1459893714190822\n",
      "reported_inter-annotator_agree\n",
      "0.1211357811559225\n",
      "total_num_of_human_annotators\n",
      "0.28141508841358065\n",
      "median_num_of_annotators_per_i\n",
      "0.26144640785109685\n",
      "link_to_dataset_available\n",
      "0.3217499138905462\n"
     ]
    }
   ],
   "source": [
    "ka_dict = {}\n",
    "for sheet in list(df.keys()):\n",
    "    sheet_df = df[sheet].melt(id_vars=\"URL hash\")\n",
    "    print(sheet)\n",
    "    ka_dict[sheet] = simpledorff.calculate_krippendorffs_alpha_for_df(sheet_df,experiment_col='URL hash',\n",
    "                                                 annotator_col='variable',\n",
    "                                                 class_col='value')\n",
    "    print(ka_dict[sheet])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform results into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ka_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original_classification_task</th>\n",
       "      <td>0.670469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification_outcome</th>\n",
       "      <td>0.520310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels_from_human_annotation</th>\n",
       "      <td>0.517078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human_annotation_for_training_</th>\n",
       "      <td>0.516876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>used_original_human_annotation</th>\n",
       "      <td>0.497642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_human_annotation_sour</th>\n",
       "      <td>0.329554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prescreening_for_crowdwork</th>\n",
       "      <td>0.097168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annotator_compensation</th>\n",
       "      <td>0.342746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_for_human_annotators</th>\n",
       "      <td>0.363974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>formal_instructions_</th>\n",
       "      <td>0.336562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_annotator_overlap</th>\n",
       "      <td>0.370313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synthesis_of_annotator_overlap</th>\n",
       "      <td>0.145989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reported_inter-annotator_agree</th>\n",
       "      <td>0.121136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_num_of_human_annotators</th>\n",
       "      <td>0.281415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_num_of_annotators_per_i</th>\n",
       "      <td>0.261446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_to_dataset_available</th>\n",
       "      <td>0.321750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ka_score\n",
       "original_classification_task    0.670469\n",
       "classification_outcome          0.520310\n",
       "labels_from_human_annotation    0.517078\n",
       "human_annotation_for_training_  0.516876\n",
       "used_original_human_annotation  0.497642\n",
       "original_human_annotation_sour  0.329554\n",
       "prescreening_for_crowdwork      0.097168\n",
       "annotator_compensation          0.342746\n",
       "training_for_human_annotators   0.363974\n",
       "formal_instructions_            0.336562\n",
       "multiple_annotator_overlap      0.370313\n",
       "synthesis_of_annotator_overlap  0.145989\n",
       "reported_inter-annotator_agree  0.121136\n",
       "total_num_of_human_annotators   0.281415\n",
       "median_num_of_annotators_per_i  0.261446\n",
       "link_to_dataset_available       0.321750"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ka_df = pd.DataFrame(ka_dict,index=[0]).T\n",
    "ka_df.columns = [\"ka_score\"]\n",
    "ka_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom agreement metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean dataset\n",
    "Using the same `clean_df()` function from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/all_labels_hashed.xlsx\", sheet_name=None, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet in list(df.keys()):\n",
    "    df[sheet] = clean_df(df[sheet])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for scoring a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_total_agree_row(row):\n",
    "    \"\"\"\n",
    "    Score the total agreement of a row of labels, ignoring blank (np.nan) values\n",
    "    \n",
    "    Parameters:\n",
    "        row (pd.Series): row name (URL hash, unused) followed by 6 labels (1 for each labeler)\n",
    "    \n",
    "    returns: \n",
    "        score (int): 1 if all non-np.nan/blank labels are the same, 0 if any difference\n",
    "    \"\"\"\n",
    "   \n",
    "    labels = row[1:7].str.lower()\n",
    "    \n",
    "    label_count = labels.value_counts(dropna=True)\n",
    "    \n",
    "    if len(label_count) <= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_correct_row(row):\n",
    "    \"\"\"\n",
    "    Score the mean agreement of a row of labels.\n",
    "    \n",
    "    Parameters:\n",
    "        row (pd.Series): row name (URL hash, unused) followed by 7 labels (6 labelers, 1 final)\n",
    "    \n",
    "    returns: \n",
    "        score (float): proportion of first 6 labels that are the same as the last\n",
    "        label.\n",
    "    \"\"\"\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "    for label in row[1:7]:\n",
    "        \n",
    "        if label == row[7]:\n",
    "            correct_count += 1\n",
    "            total_count += 1\n",
    "        elif label is np.nan:\n",
    "            pass\n",
    "        else:\n",
    "            total_count += 1\n",
    "    \n",
    "    if total_count == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return correct_count / total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with a few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL hash</th>\n",
       "      <th>Annotator 1</th>\n",
       "      <th>Annotator 2</th>\n",
       "      <th>Annotator 3</th>\n",
       "      <th>Annotator 4</th>\n",
       "      <th>Annotator 5</th>\n",
       "      <th>Annotator 6</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2421ef5ad32c44fd217fa11cae35504247a6e2b7a3f94e...</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>708fb39c97d35d9ddcf13c4cd9b9c45d810769e7f7c031...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>94ad8c9b7ec2ae92d99fe6b4a659686da9220169e67d1e...</td>\n",
       "      <td>no</td>\n",
       "      <td>answered NA</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>64b61dee6d1e73dd8a98dbfdbd2a41c13e423a3197e553...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              URL hash Annotator 1  \\\n",
       "1    2421ef5ad32c44fd217fa11cae35504247a6e2b7a3f94e...         yes   \n",
       "90   708fb39c97d35d9ddcf13c4cd9b9c45d810769e7f7c031...         yes   \n",
       "99   94ad8c9b7ec2ae92d99fe6b4a659686da9220169e67d1e...          no   \n",
       "152  64b61dee6d1e73dd8a98dbfdbd2a41c13e423a3197e553...         yes   \n",
       "\n",
       "     Annotator 2 Annotator 3 Annotator 4 Annotator 5 Annotator 6 Final  \n",
       "1            NaN         yes         yes         yes         NaN   yes  \n",
       "90           yes         yes         yes          no         yes   yes  \n",
       "99   answered NA         yes          no         yes         NaN   yes  \n",
       "152           no         yes         NaN         yes         NaN    no  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_classification_task'].iloc[[1,90,99,152]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This row should be: 1, 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      1\n",
       "90     0\n",
       "99     0\n",
       "152    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['original_classification_task'].iloc[[1,90,99,152]].apply(calc_total_agree_row,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This row should be: 1 (4/4), 0.833 (5/6), 0.4 (2/5), 0.25 (1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      1.000000\n",
       "90     0.833333\n",
       "99     0.400000\n",
       "152    0.250000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_classification_task'].iloc[[1,90,99,152]].apply(calc_mean_correct_row,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and store scores\n",
    "Iterate through each sheet. Use `apply` to calculate the score for each row, and store each row's score as a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_classification_task\n",
      "classification_outcome\n",
      "labels_from_human_annotation\n",
      "human_annotation_for_training_\n",
      "used_original_human_annotation\n",
      "original_human_annotation_sour\n",
      "prescreening_for_crowdwork\n",
      "annotator_compensation\n",
      "training_for_human_annotators\n",
      "formal_instructions_\n",
      "multiple_annotator_overlap\n",
      "synthesis_of_annotator_overlap\n",
      "reported_inter-annotator_agree\n",
      "total_num_of_human_annotators\n",
      "median_num_of_annotators_per_i\n",
      "link_to_dataset_available\n"
     ]
    }
   ],
   "source": [
    "for q in list(df.keys()):\n",
    "    print(q)\n",
    "    df[q]['total_agreement'] = df[q].apply(calc_total_agree_row,axis=1)\n",
    "    df[q]['mean_correct'] = df[q].apply(calc_mean_correct_row,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show results aggregated for each question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_classification_task\n",
      "Mean total agreement: 0.66\n",
      "Mean mean correct: 0.8479999999999996\n",
      "\n",
      "classification_outcome\n",
      "Mean total agreement: 0.345\n",
      "Mean mean correct: 0.6542500000000001\n",
      "\n",
      "labels_from_human_annotation\n",
      "Mean total agreement: 0.375\n",
      "Mean mean correct: 0.6823333333333332\n",
      "\n",
      "human_annotation_for_training_\n",
      "Mean total agreement: 0.465\n",
      "Mean mean correct: 0.772583333333333\n",
      "\n",
      "used_original_human_annotation\n",
      "Mean total agreement: 0.435\n",
      "Mean mean correct: 0.7105\n",
      "\n",
      "original_human_annotation_sour\n",
      "Mean total agreement: 0.435\n",
      "Mean mean correct: 0.7106666666666667\n",
      "\n",
      "prescreening_for_crowdwork\n",
      "Mean total agreement: 0.585\n",
      "Mean mean correct: 0.8419999999999994\n",
      "\n",
      "annotator_compensation\n",
      "Mean total agreement: 0.46\n",
      "Mean mean correct: 0.6796666666666664\n",
      "\n",
      "training_for_human_annotators\n",
      "Mean total agreement: 0.48\n",
      "Mean mean correct: 0.7\n",
      "\n",
      "formal_instructions_\n",
      "Mean total agreement: 0.475\n",
      "Mean mean correct: 0.6679166666666666\n",
      "\n",
      "multiple_annotator_overlap\n",
      "Mean total agreement: 0.485\n",
      "Mean mean correct: 0.6929166666666667\n",
      "\n",
      "synthesis_of_annotator_overlap\n",
      "Mean total agreement: 0.53\n",
      "Mean mean correct: 0.8340833333333332\n",
      "\n",
      "reported_inter-annotator_agree\n",
      "Mean total agreement: 0.555\n",
      "Mean mean correct: 0.8580833333333331\n",
      "\n",
      "total_num_of_human_annotators\n",
      "Mean total agreement: 0.505\n",
      "Mean mean correct: 0.6925833333333334\n",
      "\n",
      "median_num_of_annotators_per_i\n",
      "Mean total agreement: 0.485\n",
      "Mean mean correct: 0.693\n",
      "\n",
      "link_to_dataset_available\n",
      "Mean total agreement: 0.41\n",
      "Mean mean correct: 0.6609999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in list(df.keys()):\n",
    "    print(q)\n",
    "    print(\"Mean total agreement:\", df[q]['total_agreement'].mean())\n",
    "    print(\"Mean mean correct:\", df[q]['mean_correct'].mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert results into final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Mean total agreement</th>\n",
       "      <th>Mean mean correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Question, Mean total agreement, Mean mean correct]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(columns=(\"Question\",\"Mean total agreement\", \"Mean mean correct\"))\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = []\n",
    "for q in list(df.keys()):\n",
    "    row = {\"Question\":q,\n",
    "           \"Mean total agreement\":df[q]['total_agreement'].mean(),\n",
    "           \"Mean mean correct\":df[q]['mean_correct'].mean()\n",
    "          }\n",
    "    \n",
    "    list_of_dicts.append(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge results with Ka results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean total agreement</th>\n",
       "      <th>Mean mean correct</th>\n",
       "      <th>ka_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original_classification_task</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.670469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification_outcome</th>\n",
       "      <td>0.345</td>\n",
       "      <td>0.654250</td>\n",
       "      <td>0.520310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels_from_human_annotation</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.682333</td>\n",
       "      <td>0.517078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human_annotation_for_training_</th>\n",
       "      <td>0.465</td>\n",
       "      <td>0.772583</td>\n",
       "      <td>0.516876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>used_original_human_annotation</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.710500</td>\n",
       "      <td>0.497642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_human_annotation_sour</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.710667</td>\n",
       "      <td>0.329554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prescreening_for_crowdwork</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.097168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annotator_compensation</th>\n",
       "      <td>0.460</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.342746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_for_human_annotators</th>\n",
       "      <td>0.480</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.363974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>formal_instructions_</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.667917</td>\n",
       "      <td>0.336562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_annotator_overlap</th>\n",
       "      <td>0.485</td>\n",
       "      <td>0.692917</td>\n",
       "      <td>0.370313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synthesis_of_annotator_overlap</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.834083</td>\n",
       "      <td>0.145989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reported_inter-annotator_agree</th>\n",
       "      <td>0.555</td>\n",
       "      <td>0.858083</td>\n",
       "      <td>0.121136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_num_of_human_annotators</th>\n",
       "      <td>0.505</td>\n",
       "      <td>0.692583</td>\n",
       "      <td>0.281415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_num_of_annotators_per_i</th>\n",
       "      <td>0.485</td>\n",
       "      <td>0.693000</td>\n",
       "      <td>0.261446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_to_dataset_available</th>\n",
       "      <td>0.410</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.321750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Mean total agreement  Mean mean correct  \\\n",
       "original_classification_task                   0.660           0.848000   \n",
       "classification_outcome                         0.345           0.654250   \n",
       "labels_from_human_annotation                   0.375           0.682333   \n",
       "human_annotation_for_training_                 0.465           0.772583   \n",
       "used_original_human_annotation                 0.435           0.710500   \n",
       "original_human_annotation_sour                 0.435           0.710667   \n",
       "prescreening_for_crowdwork                     0.585           0.842000   \n",
       "annotator_compensation                         0.460           0.679667   \n",
       "training_for_human_annotators                  0.480           0.700000   \n",
       "formal_instructions_                           0.475           0.667917   \n",
       "multiple_annotator_overlap                     0.485           0.692917   \n",
       "synthesis_of_annotator_overlap                 0.530           0.834083   \n",
       "reported_inter-annotator_agree                 0.555           0.858083   \n",
       "total_num_of_human_annotators                  0.505           0.692583   \n",
       "median_num_of_annotators_per_i                 0.485           0.693000   \n",
       "link_to_dataset_available                      0.410           0.661000   \n",
       "\n",
       "                                ka_score  \n",
       "original_classification_task    0.670469  \n",
       "classification_outcome          0.520310  \n",
       "labels_from_human_annotation    0.517078  \n",
       "human_annotation_for_training_  0.516876  \n",
       "used_original_human_annotation  0.497642  \n",
       "original_human_annotation_sour  0.329554  \n",
       "prescreening_for_crowdwork      0.097168  \n",
       "annotator_compensation          0.342746  \n",
       "training_for_human_annotators   0.363974  \n",
       "formal_instructions_            0.336562  \n",
       "multiple_annotator_overlap      0.370313  \n",
       "synthesis_of_annotator_overlap  0.145989  \n",
       "reported_inter-annotator_agree  0.121136  \n",
       "total_num_of_human_annotators   0.281415  \n",
       "median_num_of_annotators_per_i  0.261446  \n",
       "link_to_dataset_available       0.321750  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(list_of_dicts)[['Question','Mean total agreement','Mean mean correct']]\n",
    "summary_df = summary_df.set_index('Question')\n",
    "summary_df = pd.concat([summary_df,ka_df],axis=1)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate means and medians across all questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mean total agreement    0.480313\n",
       "Mean mean correct       0.731224\n",
       "ka_score                0.355902\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mean total agreement    0.477500\n",
       "Mean mean correct       0.696500\n",
       "ka_score                0.339654\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = summary_df.append(pd.Series(summary_df.mean(),name=\"Average across all questions\"))\n",
    "summary_df = summary_df.append(pd.Series(summary_df.median(),name=\"Median across all questions\"))\n",
    "summary_df.columns = ['Mean total agreement', 'Mean percent correct', \"Krippendorf's alpha\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round to 3 decimal places and format first two metrics as percentages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_73370_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Mean total agreement</th>        <th class=\"col_heading level0 col1\" >Mean percent correct</th>        <th class=\"col_heading level0 col2\" >Krippendorf's alpha</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_73370_level0_row0\" class=\"row_heading level0 row0\" >original_classification_task</th>\n",
       "                        <td id=\"T_73370_row0_col0\" class=\"data row0 col0\" >66.0%</td>\n",
       "                        <td id=\"T_73370_row0_col1\" class=\"data row0 col1\" >84.8%</td>\n",
       "                        <td id=\"T_73370_row0_col2\" class=\"data row0 col2\" >0.670</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row1\" class=\"row_heading level0 row1\" >classification_outcome</th>\n",
       "                        <td id=\"T_73370_row1_col0\" class=\"data row1 col0\" >34.5%</td>\n",
       "                        <td id=\"T_73370_row1_col1\" class=\"data row1 col1\" >65.4%</td>\n",
       "                        <td id=\"T_73370_row1_col2\" class=\"data row1 col2\" >0.520</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row2\" class=\"row_heading level0 row2\" >labels_from_human_annotation</th>\n",
       "                        <td id=\"T_73370_row2_col0\" class=\"data row2 col0\" >37.5%</td>\n",
       "                        <td id=\"T_73370_row2_col1\" class=\"data row2 col1\" >68.2%</td>\n",
       "                        <td id=\"T_73370_row2_col2\" class=\"data row2 col2\" >0.517</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row3\" class=\"row_heading level0 row3\" >human_annotation_for_training_</th>\n",
       "                        <td id=\"T_73370_row3_col0\" class=\"data row3 col0\" >46.5%</td>\n",
       "                        <td id=\"T_73370_row3_col1\" class=\"data row3 col1\" >77.3%</td>\n",
       "                        <td id=\"T_73370_row3_col2\" class=\"data row3 col2\" >0.517</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row4\" class=\"row_heading level0 row4\" >used_original_human_annotation</th>\n",
       "                        <td id=\"T_73370_row4_col0\" class=\"data row4 col0\" >43.5%</td>\n",
       "                        <td id=\"T_73370_row4_col1\" class=\"data row4 col1\" >71.0%</td>\n",
       "                        <td id=\"T_73370_row4_col2\" class=\"data row4 col2\" >0.498</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row5\" class=\"row_heading level0 row5\" >original_human_annotation_sour</th>\n",
       "                        <td id=\"T_73370_row5_col0\" class=\"data row5 col0\" >43.5%</td>\n",
       "                        <td id=\"T_73370_row5_col1\" class=\"data row5 col1\" >71.1%</td>\n",
       "                        <td id=\"T_73370_row5_col2\" class=\"data row5 col2\" >0.330</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row6\" class=\"row_heading level0 row6\" >prescreening_for_crowdwork</th>\n",
       "                        <td id=\"T_73370_row6_col0\" class=\"data row6 col0\" >58.5%</td>\n",
       "                        <td id=\"T_73370_row6_col1\" class=\"data row6 col1\" >84.2%</td>\n",
       "                        <td id=\"T_73370_row6_col2\" class=\"data row6 col2\" >0.097</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row7\" class=\"row_heading level0 row7\" >annotator_compensation</th>\n",
       "                        <td id=\"T_73370_row7_col0\" class=\"data row7 col0\" >46.0%</td>\n",
       "                        <td id=\"T_73370_row7_col1\" class=\"data row7 col1\" >68.0%</td>\n",
       "                        <td id=\"T_73370_row7_col2\" class=\"data row7 col2\" >0.343</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row8\" class=\"row_heading level0 row8\" >training_for_human_annotators</th>\n",
       "                        <td id=\"T_73370_row8_col0\" class=\"data row8 col0\" >48.0%</td>\n",
       "                        <td id=\"T_73370_row8_col1\" class=\"data row8 col1\" >70.0%</td>\n",
       "                        <td id=\"T_73370_row8_col2\" class=\"data row8 col2\" >0.364</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row9\" class=\"row_heading level0 row9\" >formal_instructions_</th>\n",
       "                        <td id=\"T_73370_row9_col0\" class=\"data row9 col0\" >47.5%</td>\n",
       "                        <td id=\"T_73370_row9_col1\" class=\"data row9 col1\" >66.8%</td>\n",
       "                        <td id=\"T_73370_row9_col2\" class=\"data row9 col2\" >0.337</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row10\" class=\"row_heading level0 row10\" >multiple_annotator_overlap</th>\n",
       "                        <td id=\"T_73370_row10_col0\" class=\"data row10 col0\" >48.5%</td>\n",
       "                        <td id=\"T_73370_row10_col1\" class=\"data row10 col1\" >69.3%</td>\n",
       "                        <td id=\"T_73370_row10_col2\" class=\"data row10 col2\" >0.370</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row11\" class=\"row_heading level0 row11\" >synthesis_of_annotator_overlap</th>\n",
       "                        <td id=\"T_73370_row11_col0\" class=\"data row11 col0\" >53.0%</td>\n",
       "                        <td id=\"T_73370_row11_col1\" class=\"data row11 col1\" >83.4%</td>\n",
       "                        <td id=\"T_73370_row11_col2\" class=\"data row11 col2\" >0.146</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row12\" class=\"row_heading level0 row12\" >reported_inter-annotator_agree</th>\n",
       "                        <td id=\"T_73370_row12_col0\" class=\"data row12 col0\" >55.5%</td>\n",
       "                        <td id=\"T_73370_row12_col1\" class=\"data row12 col1\" >85.8%</td>\n",
       "                        <td id=\"T_73370_row12_col2\" class=\"data row12 col2\" >0.121</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row13\" class=\"row_heading level0 row13\" >total_num_of_human_annotators</th>\n",
       "                        <td id=\"T_73370_row13_col0\" class=\"data row13 col0\" >50.5%</td>\n",
       "                        <td id=\"T_73370_row13_col1\" class=\"data row13 col1\" >69.3%</td>\n",
       "                        <td id=\"T_73370_row13_col2\" class=\"data row13 col2\" >0.281</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row14\" class=\"row_heading level0 row14\" >median_num_of_annotators_per_i</th>\n",
       "                        <td id=\"T_73370_row14_col0\" class=\"data row14 col0\" >48.5%</td>\n",
       "                        <td id=\"T_73370_row14_col1\" class=\"data row14 col1\" >69.3%</td>\n",
       "                        <td id=\"T_73370_row14_col2\" class=\"data row14 col2\" >0.261</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row15\" class=\"row_heading level0 row15\" >link_to_dataset_available</th>\n",
       "                        <td id=\"T_73370_row15_col0\" class=\"data row15 col0\" >41.0%</td>\n",
       "                        <td id=\"T_73370_row15_col1\" class=\"data row15 col1\" >66.1%</td>\n",
       "                        <td id=\"T_73370_row15_col2\" class=\"data row15 col2\" >0.322</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row16\" class=\"row_heading level0 row16\" >Average across all questions</th>\n",
       "                        <td id=\"T_73370_row16_col0\" class=\"data row16 col0\" >48.0%</td>\n",
       "                        <td id=\"T_73370_row16_col1\" class=\"data row16 col1\" >73.1%</td>\n",
       "                        <td id=\"T_73370_row16_col2\" class=\"data row16 col2\" >0.356</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73370_level0_row17\" class=\"row_heading level0 row17\" >Median across all questions</th>\n",
       "                        <td id=\"T_73370_row17_col0\" class=\"data row17 col0\" >48.0%</td>\n",
       "                        <td id=\"T_73370_row17_col1\" class=\"data row17 col1\" >70.0%</td>\n",
       "                        <td id=\"T_73370_row17_col2\" class=\"data row17 col2\" >0.343</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5ca11970d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_style = {\n",
    "    'Mean total agreement': '{:,.1%}'.format,\n",
    "    'Mean percent correct': '{:,.1%}'.format,\n",
    "    \"Krippendorf's alpha\": '{:,.3f}'.format,\n",
    "}\n",
    "\n",
    "summary_df.style.format(df_style)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export results with per-row scores to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('../data/all_labels_with_irr_hashed.xlsx') as writer:\n",
    "    for sheet in list(df.keys()):\n",
    "        df[sheet].to_excel(writer, sheet_name=sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
